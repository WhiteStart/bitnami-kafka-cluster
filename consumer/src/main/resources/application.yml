##服务器端口号
server:
  port: 4001

spring:
  application:
    name: consumer
  cloud:
    zookeeper:
      connect-string: 10.22.191.78:2181,10.22.191.35:2182,10.22.191.138:2183
      discovery:
        register: true
      enabled: true
      properties:
        authProvider:1: org.apache.zookeeper.server.auth.SASLAuthenticationProvider
        requireClientAuthScheme: sasl
        jaasLoginRenew: 3600000

  kafka:
    bootstrap-servers: 10.22.191.78:9094,10.22.191.35:9097,10.22.191.138:9100
    properties:
      security:
        protocol: SASL_PLAINTEXT
      sasl:
        mechanism: SCRAM-SHA-256
    consumer:
      # 默认消费者组
      group-id: test
      # earliest 从主题起始位置开始消费消息
      # latest  从最新可用偏移量开始消费
      auto-offset-reset: latest
      # 批量一次最大拉取数据量
      max-poll-records: 4000
      # true 自动提交，消息 poll 下来之后直接提交 offset，如果此时 consumer 故障，消息会丢失
      # false 手动同步/异步提交，消费完后调用同步/异步提交的方法
      enable-auto-commit: false
      # 自动提交时间间隔，单位ms
      auto-commit-interval: 1000
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      # 手动调用Acknowledgment.acknowledge()后立刻提交
      ack-mode: MANUAL_IMMEDIATE

properties:
  connect-string: 10.22.191.78:2181,10.22.191.35:2182,10.22.191.138:2183
  sessionTimeout: 5000
  connectionTimeout: 5000
  registrationPath: /services
  username: user
  password: password